<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-E00L9PT3V9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-E00L9PT3V9');
  </script>
  <title>{{ site.name }}</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Zhenghao Xu
              </h1>
              <p>
                I am a fourth-year PhD candidate at
                <a href="https://www.gatech.edu/">Georgia Tech</a> in the
                <a href="https://ml.cc.gatech.edu/">Machine Learning program</a>, advised by
                Prof. <a href="https://www2.isye.gatech.edu/~tzhao80/">Tuo Zhao</a> and
                Prof. <a href="https://mtao8.math.gatech.edu/">Molei Tao</a> (co-advise). 
                Before joining Georgia Tech, I received my bachelor's degree in Computer Science and Technology from
                <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, where I was a member of the
                Qiushi Science Class (Computer Science).
              </p>
              <p style="text-align:center">
                <a href="mailto:zhenghaoxu@gatech.edu">Email</a> &nbsp;/&nbsp;
                <!-- <a href="mailto:smileandyxu@gmail.com">Email (personal)</a> &nbsp;/&nbsp; -->
                <a href="https://github.com/zhenghaoxu-gatech">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=FRegzp4AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/zhenghaoxu/">LinkedIn</a> &nbsp;/&nbsp;
                <a href="https://x.com/ZhenghaoXu0">X (Twitter)</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="{{ site.avatar | relative_url }}">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                My current research focuses on reinforcement learning (RL) and its application in LLM post-training.
                <!-- I work on both theory and practice, aiming to bridge the gap between them and translate mathematical insights -->
                <!-- into practically scalable algorithms.  -->
                I am also interested in continuous optimization and deep learning theory.
              </p>
              <h2>Selected Papers</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h3>Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training</h3>
              <br>
              <strong>Zhenghao Xu</strong>, Qin Lu, Changlong Yu, Tuo Zhao
              <br>
              <em>arXiv</em>, 2026
              <br>
              <a href="https://arxiv.org/pdf/2602.05933">paper</a> /
              <a href="https://github.com/horizon-rl/OpenKimi">code</a> /
              <a href="https://zhenghaoxu.notion.site/Revisiting-Kimi-s-Policy-Mirror-Descent-2fe7f18c8c2a801ba0d5fba25690f5ce">blog (Revisiting (Kimi's) Policy Mirror Descent)</a>
              <p></p>
              Policy mirror descent for LLM post-training with an implicit regularization perspective.
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h3>Ask a Strong LLM Judge when Your Reward Model is Uncertain</h3>
              <br>
              <strong>Zhenghao Xu</strong>, Qin Lu, Qingru Zhang, Liang Qiu, Ilgee Hong, Changlong Yu, Wenlin Yao, Yao Liu, Haoming Jiang, Lihong Li, Hyokun Yun, Tuo Zhao
              <br>
              <em>NeurIPS</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2510.20369">paper</a> /
              <a href="https://github.com/horizon-rl/uncertainty-router">code</a>
              <p></p>
              Uncertainty-based routing between reward models and strong LLM judges for efficient pairwise RLHF.
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h3>Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds</h3>
              <br>
              <strong>Zhenghao Xu</strong>, Xiang Ji, Minshuo Chen, Mengdi Wang, Tuo Zhao
              <br>
              <em>JMLR</em>, 2024
              <br>
              <a href="https://www.jmlr.org/papers/volume25/24-0066/24-0066.pdf">paper</a> /
              <a href="https://github.com/zhenghaoxu-gatech/Neural-Policy-Mirror-Descent">code</a>
              <p></p>
              Theory for policy optimization with neural function approximation under low-dimensional structure.
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h3>Provable Acceleration of Nesterov's Accelerated Gradient for Rectangular Matrix Factorization and Linear Neural Networks</h3>
              <br>
              <strong>Zhenghao Xu</strong>, Yuqing Wang, Tuo Zhao, Rachel Ward, Molei Tao
              <br>
              <em>NeurIPS</em>, 2024
              <br>
              <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/3b4e1336f775c3dba16ebbb8d2afd258-Paper-Conference.pdf">paper</a>
              <p></p>
              Acceleration and low-rank adaptivity guarantees for Nesterov's method in matrix factorization and linear networks.
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h3>Good Regularity Creates Large Learning Rate Implicit Biases: Edge of Stability, Balancing, and Catapult</h3>
              <br>
              Yuqing Wang, <strong>Zhenghao Xu</strong>, Tuo Zhao, Molei Tao
              <br>
              <em>JMLR</em>, accepted (to appear)
              <br>
              <a href="https://arxiv.org/pdf/2310.17087">paper</a> /
              <a href="https://openreview.net/pdf?id=6O15A3h2yl">short version (M3L@NeurIPS 2023)</a>
              <p></p>
              Large learning rate dynamics in nonconvex optimization, including edge of stability, balancing, and catapult.
            </td>
          </tr>
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Selected Projects</h2>
              <p>Use this section for non-paper projects, demos, internships, or open-source work.</p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <!-- Paste your selected projects here as repeated <tr> blocks. -->
          <!-- You can reuse the same <tr> structure as in the Research section above. -->
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

